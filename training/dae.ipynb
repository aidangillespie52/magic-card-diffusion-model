{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory (where the notebook is located)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append('../models')\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from random import randint\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autoencoder import ResNetAutoencoder\n",
    "from dae import DenoisingAutoencoder\n",
    "from mtg_cards_dataset import MTGCardsDataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 1\n",
    "LOGGING_INTERVAL = 150\n",
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = True\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "])\n",
    "\n",
    "dataset = MTGCardsDataset(DATA_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = ResNetAutoencoder()\n",
    "autoencoder.to(device)\n",
    "autoencoder.load_state_dict(torch.load('trained_models/autoencoder.pth'))\n",
    "\n",
    "dae = DenoisingAutoencoder()\n",
    "dae.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(dae.parameters(), lr=1e-3)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    dae.load_state_dict(torch.load('trained_models/dae.pth'))\n",
    "    \n",
    "# Training Loop\n",
    "num_epochs = 2\n",
    "dae.train()  # Set the DAE to training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (clean_images, _) in enumerate(dataloader):  # Load only clean images from the dataset\n",
    "        clean_images = clean_images.to(device)\n",
    "        \n",
    "        # Generate noisy images using the noisy image generator\n",
    "        with torch.no_grad():  # No need to calculate gradients for the noisy generator\n",
    "            noisy_images = autoencoder(clean_images)\n",
    "        \n",
    "        # Forward Pass through DAE\n",
    "        denoised_images = dae(noisy_images)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = loss_fn(denoised_images, clean_images)  # Compare with the original clean images\n",
    "        \n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if i % LOGGING_INTERVAL == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}, Loss: {loss.item()}\")\n",
    "            idx = randint(0, len(dataset))\n",
    "            img, _ = dataset[idx]\n",
    "            dae.test(img)\n",
    "\n",
    "            # Save model if required\n",
    "            if SAVE_MODEL:\n",
    "                print('SAVING MODEL. DO NOT INTERRUPT!')\n",
    "                torch.save(dae.state_dict(), 'trained_models/dae.pth')\n",
    "                print('MODEL SAVED!')\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(dataloader):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
